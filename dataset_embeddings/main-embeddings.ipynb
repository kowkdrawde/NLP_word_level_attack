{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8fb6a0b-f6d4-4649-ae5c-6bccc44bea08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install textattack[tensorflow,optional]\n",
    "#!pip install -U datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6a32e48-d2fa-4420-8c45-3f9fe99d0526",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\tf\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] 找不到指定的程序。'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "D:\\anaconda3\\envs\\tf\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "D:\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "D:\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision\n",
    "import tensorflow as tf\n",
    "import transformers\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "\n",
    "import textattack\n",
    "from textattack.models.wrappers import HuggingFaceModelWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e13b205-9c12-4f2e-9bcb-b7a26f7a0f7f",
   "metadata": {},
   "source": [
    "### BERT-based-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ece98501-61d1-44c5-946e-b4b41e046d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\tf\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# bert-based-uncased\n",
    "model_path1 = 'bert-base-uncased'\n",
    "\n",
    "bert_model = transformers.AutoModel.from_pretrained(model_path1)\n",
    "bert_tokenizer = transformers.AutoTokenizer.from_pretrained(model_path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e87d4a7c-15a7-4ba8-bd9d-4d0ef5c2c97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mag_news\u001b[0m, split \u001b[94mtest\u001b[0m.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".......0:13:04.945165\n"
     ]
    }
   ],
   "source": [
    "# obtain BERT encoding\n",
    "\n",
    "cnt = 0\n",
    "path = 'dataset_embeddings/bertagnewstest.txt'      # path\n",
    "ds = textattack.datasets.HuggingFaceDataset('ag_news', split='test')                               # train dataset\n",
    "#path = 'dataset_embeddings/bertmrtest.txt'      # path\n",
    "#ds = test_dataset                               # train dataset\n",
    "\n",
    "st = datetime.datetime.now()\n",
    "\n",
    "with open(path, 'w') as f:\n",
    "    for text, label in ds:\n",
    "        cnt += 1\n",
    "        t = bert_tokenizer(text['text'], return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        t = bert_model(**t).pooler_output.detach().numpy()\n",
    "        \n",
    "        np.savetxt(f, np.append(t, label).reshape(1,-1), delimiter=',')\n",
    "        f.write('\\n')\n",
    "        \n",
    "        if cnt%1000 == 0:\n",
    "            print('.',end='')\n",
    "\n",
    "et = datetime.datetime.now()\n",
    "print(et-st)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd63a478-d62b-479e-8008-00fbd17c8c18",
   "metadata": {},
   "source": [
    "### DistilBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "91393671-12a7-44c0-8741-fc22fbb0bbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\tf\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Distilbert-based-uncased\n",
    "model_path2 = 'distilbert/distilbert-base-uncased'\n",
    "\n",
    "disbert_model = transformers.AutoModel.from_pretrained(model_path2)\n",
    "disbert_tokenizer = transformers.AutoTokenizer.from_pretrained(model_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d94dc42e-b681-44f1-90fc-9d235e49234f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mag_news\u001b[0m, split \u001b[94mtrain\u001b[0m.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................................................................................................................1:47:00.250764\n"
     ]
    }
   ],
   "source": [
    "# obtain DistilBERT encoding\n",
    "\n",
    "cnt = 0\n",
    "path = 'dataset_embeddings/disbertagnewstrain.txt'      # path\n",
    "ds = textattack.datasets.HuggingFaceDataset('ag_news', split='train')                               # train dataset\n",
    "#path = 'dataset_embeddings/bertmrtest.txt'      # path\n",
    "#ds = test_dataset                               # train dataset\n",
    "\n",
    "st = datetime.datetime.now()\n",
    "\n",
    "with open(path, 'w') as f:\n",
    "    for text, label in ds:\n",
    "        cnt += 1\n",
    "        t = disbert_tokenizer(text['text'], return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        t = disbert_model(**t).last_hidden_state.detach().numpy().mean(axis=1)\n",
    "        \n",
    "        np.savetxt(f, np.append(t, label).reshape(1,-1), delimiter=',')\n",
    "        f.write('\\n')\n",
    "        \n",
    "        if cnt%1000 == 0:\n",
    "            print('.',end='')\n",
    "\n",
    "et = datetime.datetime.now()\n",
    "print(et-st)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f01fff-dcd8-43f2-9b5b-d84826b7029b",
   "metadata": {},
   "source": [
    "### CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91dc94fc-775d-4ee6-ba68-20bee81b8148",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\tf\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load CLIP model and processor\n",
    "model_name = \"openai/clip-vit-base-patch32\"\n",
    "clip_processor = CLIPProcessor.from_pretrained(model_name)\n",
    "clip_model = CLIPModel.from_pretrained(model_name)\n",
    "\n",
    "# Access text encoder\n",
    "text_encoder = clip_model.text_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "534a28d8-0e78-40e4-ac5c-5eeb924e2b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mag_news\u001b[0m, split \u001b[94mtest\u001b[0m.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".......0:08:27.974111\n"
     ]
    }
   ],
   "source": [
    "# obtain clip encoding\n",
    "\n",
    "cnt = 0\n",
    "path = 'dataset_embeddings/clipagnewstest.txt'      # path\n",
    "ds = textattack.datasets.HuggingFaceDataset('ag_news', split='test')                               # train dataset\n",
    "\n",
    "st = datetime.datetime.now()\n",
    "\n",
    "with open(path, 'w') as f:\n",
    "    for text, label in ds:\n",
    "        cnt += 1\n",
    "        t = clip_processor(text['text'], return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        t = text_encoder(**t).pooler_output.detach().numpy()\n",
    "        \n",
    "        np.savetxt(f, np.append(t, label).reshape(1,-1), delimiter=',')\n",
    "        f.write('\\n')\n",
    "        \n",
    "        if cnt%1000 == 0:\n",
    "            print('.',end='')\n",
    "\n",
    "et = datetime.datetime.now()\n",
    "print(et-st)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
